{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8089266,"sourceType":"datasetVersion","datasetId":4775518},{"sourceId":8089281,"sourceType":"datasetVersion","datasetId":4775527},{"sourceId":12650227,"sourceType":"datasetVersion","datasetId":7994437},{"sourceId":470644,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":379672,"modelId":399557},{"sourceId":593572,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":444208,"modelId":460697}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset,TensorDataset, WeightedRandomSampler, RandomSampler\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\nimport wandb\nfrom omegaconf import OmegaConf\nimport os\nimport warnings\nfrom kaggle_secrets import UserSecretsClient\nimport time\nimport psutil\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score\nimport networkx as nx\nimport igraph as ig\nimport json\n# change 1.02\n# import /kaggle/input/centrality_network/pytorch/default/1 as network\nimport sys\nsys.path.append(\"/kaggle/input/centrality_network/pytorch/default/1\")\n\nfrom network_features import separate_graph, cal_betweenness_centrality, cal_k_core, cal_k_truss\nfrom CommCentralityCode import comm_centreality\nfrom modularity_vitality import modularity_vitality\n\nsys.path.append(\"/kaggle/input/githubrepofiles/pytorch/default/1\")\nfrom src.dataset.dataset_info import datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:53:46.814955Z","iopub.execute_input":"2025-10-27T08:53:46.815705Z","iopub.status.idle":"2025-10-27T08:54:11.216788Z","shell.execute_reply.started":"2025-10-27T08:53:46.815679Z","shell.execute_reply":"2025-10-27T08:54:11.216110Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# name = \"cic_ton_iot_5_percent\"\nname = \"cic_ton_iot\"\n# name = \"cic_ids_2017_5_percent\"\n# name = \"cic_ids_2017\"\nNO_NODE_FEATURE=True # False: centrality added  True: centality not used\n\ndataset = datasets[name]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.217894Z","iopub.execute_input":"2025-10-27T08:54:11.218383Z","iopub.status.idle":"2025-10-27T08:54:11.222280Z","shell.execute_reply.started":"2025-10-27T08:54:11.218362Z","shell.execute_reply":"2025-10-27T08:54:11.221717Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\n# change 1.04\ndef add_centralities(df, new_path, graph_path, dataset, cn_measures, network_features):\n# def add_centralities(df, new_path, graph_path, dataset, cn_measures):\n        # change 1.05\n    # G = nx.from_pandas_edgelist(df, source=\"Src IP\",target=\"Dst IP\", create_using=nx.DiGraph())\n    if NO_NODE_FEATURE:\n        print(\"NO node features added\")\n        return df\n    G = nx.from_pandas_edgelist( df, source=dataset.src_ip_col, target=dataset.dst_ip_col, create_using=nx.DiGraph())\n    G.remove_nodes_from(list(nx.isolates(G)))\n    for node in G.nodes():\n        G.nodes[node]['label'] = node\n\n    G1 = ig.Graph.from_networkx(G)\n    labels = [G.nodes[node]['label'] for node in G.nodes()]\n    G1.vs['label'] = labels\n\n    part = G1.community_infomap()\n    communities = []\n    for com in part:\n        communities.append([G1.vs[node_index]['label'] for node_index in com])\n\n    community_labels = {}\n    for i, community in enumerate(communities):\n        for node in community:\n            community_labels[node] = i\n\n    nx.set_node_attributes(G, community_labels, \"new_community\")\n\n    intra_graph, inter_graph = separate_graph(G, communities)\n\n    if \"betweenness\" in cn_measures:\n        nx.set_node_attributes(G, cal_betweenness_centrality(G), \"betweenness\")\n        print(\"calculated betweenness\")\n    if \"local_betweenness\" in cn_measures:\n        nx.set_node_attributes(G, cal_betweenness_centrality(\n            intra_graph), \"local_betweenness\")\n        print(\"calculated local_betweenness\")\n    if \"global_betweenness\" in cn_measures:\n        nx.set_node_attributes(G, cal_betweenness_centrality(\n            inter_graph), \"global_betweenness\")\n        print(\"calculated global_betweenness\")\n    if \"degree\" in cn_measures:\n        nx.set_node_attributes(G, nx.degree_centrality(G), \"degree\")\n        print(\"calculated degree\")\n    if \"local_degree\" in cn_measures:\n        nx.set_node_attributes(\n            G, nx.degree_centrality(intra_graph), \"local_degree\")\n        print(\"calculated local_degree\")\n    if \"global_degree\" in cn_measures:\n        nx.set_node_attributes(G, nx.degree_centrality(\n            inter_graph), \"global_degree\")\n        print(\"calculated global_degree\")\n    if \"eigenvector\" in cn_measures:\n        nx.set_node_attributes(G, nx.eigenvector_centrality(\n            G, max_iter=600), \"eigenvector\")\n        print(\"calculated eigenvector\")\n    if \"local_eigenvector\" in cn_measures:\n        nx.set_node_attributes(G, nx.eigenvector_centrality(\n            intra_graph), \"local_eigenvector\")\n        print(\"calculated local_eigenvector\")\n    if \"global_eigenvector\" in cn_measures:\n        nx.set_node_attributes(G, nx.eigenvector_centrality(\n            inter_graph), \"global_eigenvector\")\n        print(\"calculated global_eigenvector\")\n    if \"closeness\" in cn_measures:\n        nx.set_node_attributes(G, nx.closeness_centrality(G), \"closeness\")\n        print(\"calculated closeness\")\n    if \"local_closeness\" in cn_measures:\n        nx.set_node_attributes(G, nx.closeness_centrality(\n            intra_graph), \"local_closeness\")\n        print(\"calculated local_closeness\")\n    if \"global_closeness\" in cn_measures:\n        nx.set_node_attributes(G, nx.closeness_centrality(\n            inter_graph), \"global_closeness\")\n        print(\"calculated global_closeness\")\n    if \"pagerank\" in cn_measures:\n        nx.set_node_attributes(G, nx.pagerank(G, alpha=0.85), \"pagerank\")\n        print(\"calculated pagerank\")\n    if \"local_pagerank\" in cn_measures:\n        nx.set_node_attributes(G, nx.pagerank(\n            intra_graph, alpha=0.85), \"local_pagerank\")\n        print(\"calculated local_pagerank\")\n    if \"global_pagerank\" in cn_measures:\n        nx.set_node_attributes(G, nx.pagerank(\n            inter_graph, alpha=0.85), \"global_pagerank\")\n        print(\"calculated global_pagerank\")\n    if \"k_core\" in cn_measures:\n        nx.set_node_attributes(G, cal_k_core(G), \"k_core\")\n        print(\"calculated k_core\")\n    if \"k_truss\" in cn_measures:\n        nx.set_node_attributes(G, cal_k_truss(G), \"k_truss\")\n        print(\"calculated k_truss\")\n    if \"Comm\" in cn_measures:\n        nx.set_node_attributes(\n            G, comm_centreality(G, community_labels), \"Comm\")\n        print(\"calculated Comm\")\n    if \"mv\" in cn_measures:\n        nx.set_node_attributes(G, modularity_vitality(G1, part), \"mv\")\n        print(\"calculated mv\")\n\n    # nx.write_gexf(G, graph_path)\n\n    features_dicts = {}\n    for measure in cn_measures:\n        features_dicts[measure] = nx.get_node_attributes(G, measure)\n        print(f\"==>> features_dicts: {measure , len(features_dicts[measure])}\")\n\n    for feature in network_features:\n        if feature[:3] == \"src\":\n            df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(\n                row[dataset.src_ip_col], -1), axis=1)\n            # df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(\n                # row['Src Ip'], -1), axis=1)\n        if feature[:3] == \"dst\":\n            df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(\n                row[dataset.dst_ip_col], -1), axis=1)\n            # df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(row['Dst IP'], -1), axis=1)\n    print(f\"--------------------------  writting the DataFrame to {new_path} ----------------------\")\n    df.to_parquet(new_path)\n    print(f\"--------------------------DataFrame written to {new_path} --------------------------\")\n    # print(df.columns)\n    # return network_features\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.223116Z","iopub.execute_input":"2025-10-27T08:54:11.223417Z","iopub.status.idle":"2025-10-27T08:54:11.515770Z","shell.execute_reply.started":"2025-10-27T08:54:11.223389Z","shell.execute_reply":"2025-10-27T08:54:11.514991Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\n\n# CHANGE 1.02\nnew_path = os.path.join(\"/kaggle/working/\",f\"{name}_with_centralities.parquet\")\ngraph_path = os.path.join(\"/kaggle/working/\",f\"{name}_graph.gpickle\")\n# cn_measures = [\"degree\", \"betweenness\", \"closeness\", \"eigenvector\"]\ncn_measures = [\"betweenness\", \"degree\", \"pagerank\", \"closeness\", \"k_truss\"]\nnetwork_features = ['src_betweenness', 'dst_betweenness', 'src_degree', 'dst_degree', 'src_pagerank', 'dst_pagerank', 'src_closeness', 'dst_closeness', 'src_k_truss', 'dst_k_truss']\nif name==\"cic_ids_2017\":\n    # Optimized Configuration\n    config = OmegaConf.create({\n        \"wandb\": {\n            \"project\": \"DL-NIDS-2--cic-ids-2017\",\n            \"entity\": \"mohammad-fleity-lebanese-university\",\n            \"tags\": [\"GRU\", \"CIC-IDS-2017\", \"PyTorch\"],\n            \"notes\": \"Optimized GRU for network intrusion detection\",\n        },\n        \"model\": {\n            \"hidden_size\": 128,          # Increased capacity\n            \"num_layers\": 2,             # Deeper network\n            \"dropout\": 0.4,              # Stronger regularization\n            \"dense_units\": [128, 64],    # Better feature extraction\n            \"learning_rate\": 0.0001,     # Slower learning\n            \"weight_decay\": 1e-4         # Stronger L2 regularization\n        },\n        \"training\": {\n            \"sequence_length\": 5,        # Longer temporal context\n            \"batch_size\": 256,           # Larger batches\n            \"max_epochs\": 15,            # More training time\n            # \"max_epochs\": 1,            # More training time\n            \"early_stopping_patience\": 7,# More patience\n            \"oversample\": True,          # Class balancing\n            \"gpus\": 1 if torch.cuda.is_available() else 0,\n            \"train_size\": 0.7,           # Proper train/val split\n            \"val_size\": 0.15             # 70/15/15 split\n        },\n        \"data\": {\n            \"raw\": \"cic_ids_2017.parquet\",\n            \"num_workers\": 4\n        }\n    })\n    dataset_name=\"CIC_IDS_2017\"\nelif name ==\"cic_ton_iot\":\n    config = OmegaConf.create({\n        \"wandb\": {\n            \"project\": \"DL-NIDS-2--cic-ton-iot\",\n            \"entity\": \"mohammad-fleity-lebanese-university\",\n            \"tags\": [\"GRU\", \"CIC-TON-IOT\", \"PyTorch\"],\n            \"notes\": \"Optimized GRU for network intrusion detection\"\n        },\n        \"model\": {\n            \"hidden_size\": 128,          # Increased capacity\n            \"num_layers\": 2,             # Deeper network\n            \"dropout\": 0.4,              # Stronger regularization\n            \"dense_units\": [128, 64],    # Better feature extraction\n            \"learning_rate\": 0.0001,     # Slower learning\n            \"weight_decay\": 1e-4         # Stronger L2 regularization\n        },\n        \"training\": {\n            \"sequence_length\": 5,        # Longer temporal context\n            \"batch_size\": 256,           # Larger batches\n            \"max_epochs\": 15,            # More training time\n            # \"max_epochs\": 1,            # More training time\n            \"early_stopping_patience\": 7,# More patience\n            \"oversample\": True,          # Class balancing\n            \"gpus\": 1 if torch.cuda.is_available() else 0,\n            \"train_size\": 0.7,           # Proper train/val split\n            \"val_size\": 0.15             # 70/15/15 split\n        },\n        \"data\": {\n            \"raw\": \"cic_ton_iot.parquet\",\n            \"num_workers\": 4\n        }\n    })\n    dataset_name=\"CIC_TON_IOT\"\n    \nelif name ==\"cic_ids_2017_5_percent\": # THIS IS JUST FOR TESTING THE FUNCTIONALITIES FASTER\n    config = OmegaConf.create({\n        \"wandb\": {\n            \"project\": \"DL-NIDS-2--cic-ton-iot\",\n            \"entity\": \"mohammad-fleity-lebanese-university\",\n            \"tags\": [\"GRU\", \"CIC-TON-IOT\", \"PyTorch\"],\n            \"notes\": \"Optimized GRU for network intrusion detection\"\n        },\n        \"model\": {\n            \"hidden_size\": 128,          # Increased capacity\n            \"num_layers\": 2,             # Deeper network\n            \"dropout\": 0.4,              # Stronger regularization\n            \"dense_units\": [128, 64],    # Better feature extraction\n            \"learning_rate\": 0.0001,     # Slower learning\n            \"weight_decay\": 1e-4         # Stronger L2 regularization\n        },\n        \"training\": {\n            \"sequence_length\": 5,        # Longer temporal context\n            \"batch_size\": 256,           # Larger batches\n            \"max_epochs\": 1,            # More training time\n            \"early_stopping_patience\": 7,# More patience\n            \"oversample\": True,          # Class balancing\n            \"gpus\": 1 if torch.cuda.is_available() else 0,\n            \"train_size\": 0.7,           # Proper train/val split\n            \"val_size\": 0.15             # 70/15/15 split\n        },\n        \"data\": {\n            \"raw\": \"cic_ids_2017_5_percent.parquet\",\n            \"num_workers\": 4\n        }\n    })\n    dataset_name=\"cic_ids_2017_5_percent\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.517681Z","iopub.execute_input":"2025-10-27T08:54:11.517911Z","iopub.status.idle":"2025-10-27T08:54:11.542431Z","shell.execute_reply.started":"2025-10-27T08:54:11.517893Z","shell.execute_reply":"2025-10-27T08:54:11.541924Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def calculate_fpr_fnr_with_global(cm):\n    \"\"\"\n    Calculate FPR and FNR for each class and globally for a multi-class confusion matrix.\n\n    Parameters:\n        cm (numpy.ndarray): Confusion matrix of shape (num_classes, num_classes).\n\n    Returns:\n        dict: A dictionary containing per-class and global FPR and FNR.\n    \"\"\"\n    num_classes = cm.shape[0]\n    results = {\"per_class\": {}, \"global\": {}}\n\n    # Initialize variables for global calculation\n    total_TP = 0\n    total_FP = 0\n    total_FN = 0\n    total_TN = 0\n\n    # Per-class calculation\n    for class_idx in range(num_classes):\n        TP = cm[class_idx, class_idx]\n        FN = np.sum(cm[class_idx, :]) - TP\n        FP = np.sum(cm[:, class_idx]) - TP\n        TN = np.sum(cm) - (TP + FP + FN)\n\n        # Calculate FPR and FNR for this class\n        FPR = FP / (FP + TN) if (FP + TN) != 0 else None\n        FNR = FN / (TP + FN) if (TP + FN) != 0 else None\n\n        # Store per-class results\n        results[\"per_class\"][class_idx] = {\"FPR\": FPR, \"FNR\": FNR}\n\n        # Update global counts\n        total_TP += TP\n        total_FP += FP\n        total_FN += FN\n        total_TN += TN\n\n    # Global calculation\n    global_FPR = total_FP / \\\n        (total_FP + total_TN) if (total_FP + total_TN) != 0 else None\n    global_FNR = total_FN / \\\n        (total_FN + total_TP) if (total_FN + total_TP) != 0 else None\n\n    results[\"global\"][\"FPR\"] = global_FPR\n    results[\"global\"][\"FNR\"] = global_FNR\n\n    return results\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.543175Z","iopub.execute_input":"2025-10-27T08:54:11.543412Z","iopub.status.idle":"2025-10-27T08:54:11.565568Z","shell.execute_reply.started":"2025-10-27T08:54:11.543396Z","shell.execute_reply":"2025-10-27T08:54:11.565020Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\nclass NIDSDataModule(pl.LightningDataModule):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        self.batch_size = config.training.batch_size\n        self.sequence_length = config.training.sequence_length\n        self.num_workers = config.data.num_workers\n        self.oversample = config.training.oversample\n        self.non_numeric_cols=[]\n        self.scaler=None\n        self.alpha = 0.5\n\n    def prepare_data(self):\n        print(f\"--------------------- {name}-parquet -----------------------\")\n        if not os.path.exists(new_path):\n            print(\"--------------------- Centralities Calculations  -----------------------\")\n            if dataset_name==\"CIC_IDS_2017\":\n                df = pd.read_parquet(os.path.join('/kaggle/input/cic-ids-2017-parquet', self.config.data.raw))\n                # print(\"--------------------- cic-ids-2017-parquet -----------------------\")\n            elif dataset_name==\"CIC_TON_IOT\":\n                df = pd.read_parquet(os.path.join('/kaggle/input/cic-ton-iot-parquet', self.config.data.raw))\n                # print(\"--------------------- cic-ton-iot-parquet -----------------------\")\n            elif dataset_name==\"cic_ids_2017_5_percent\":\n                df = pd.read_parquet(os.path.join('/kaggle/input/cic-ids-2017-5-percent', self.config.data.raw))\n                # print(\"--------------------- /kaggle/input/cic-ids-2017-5-percent -----------------------\")\n    \n            print(\"Clean data\")\n            df.replace([np.inf, -np.inf], np.nan, inplace=True)\n            df.dropna(inplace=True)\n            df.drop_duplicates(inplace=True)\n            \n            print(\"Reset index after cleaning\")\n            df = df.reset_index(drop=True)\n            \n            print(\"Identify non-numeric columns\")\n            self.non_numeric_cols = ['Label', 'Timestamp', 'Flow ID', 'Src IP', \n                                     'Src Port', 'Attack', 'Dst IP', 'Dst Port', 'Protocol']\n            self.non_numeric_cols = [col for col in self.non_numeric_cols if col in df.columns]\n    \n    \n            print(\"Encode labels\")\n            self.label_encoder = LabelEncoder()\n            df['Label_Num'] = self.label_encoder.fit_transform(df['Attack'])\n            self.classes = self.label_encoder.classes_\n            \n            # print(\"Initialize scaler\")\n            # self.scaler = StandardScaler()\n            # CHANGE 1.01\n            # print(\"Calculate Centralities start\")\n            print(\"--------------------- Centralities Calculations starting-----------------------\")\n            df = add_centralities(\n                df= df,\n                new_path=new_path,\n                graph_path=graph_path,\n                dataset=dataset,\n                cn_measures=cn_measures,\n                network_features=network_features\n            )\n        else:\n            # print(new_path,\" exist now!\")\n            print(\"--------------------- Centralities Extractions  -----------------------\")\n            df = pd.read_parquet(new_path)\n        # CHANGES TO REMOVE use only for test with 5_perecent \n        if dataset_name==\"cic_ids_2017_5_percent\":\n            multiplier = 5  # change as you wish\n    \n            target_substring = \"Sql Injection\"\n            target_rows = df[df['Attack'].str.contains(target_substring, na=False)]\n            \n            if target_rows.empty:\n                print(f\"Warning: no rows found matching '{target_substring}' in train set.\")\n            else:\n                duplicated_block = pd.concat([target_rows] * (multiplier - 1), ignore_index=True)\n                df = pd.concat([df, duplicated_block], ignore_index=True)\n                print(f\"Duplicated target class rows by factor {multiplier}. New count:\",\n                  df['Attack'].str.contains(target_substring, na=False).sum())\n            \n            \n            \n        print(\"\\n===== Class Distribution =====\")\n        counts = df[\"Attack\"].value_counts()\n        print(counts)\n        # print()\n        print(\"Initialize scaler\")\n        self.scaler = StandardScaler()\n        print(\"Train/Val/Test split\")\n        train_df, test_df = train_test_split(\n            df,\n            test_size=1 - self.config.training.train_size,\n            random_state=42,\n            stratify=df['Label_Num']\n        )\n        val_df, test_df = train_test_split(\n            test_df,\n            test_size=0.5,\n            random_state=42,\n            stratify=test_df['Label_Num']\n        )\n        # Reset indices after splitting\n        train_df = train_df.reset_index(drop=True)\n        val_df = val_df.reset_index(drop=True)\n        test_df = test_df.reset_index(drop=True)\n        \n        # Use `fit=True` only for training data\n        self.X_train, self.y_train = self._prepare_features(train_df, fit=True)\n        self.X_val, self.y_val = self._prepare_features(val_df, fit=False)\n        self.X_test, self.y_test = self._prepare_features(test_df, fit=False)\n        # print(\"Val:\\n\", val_df['Label_Num'].value_counts(normalize=True).sort_index())\n        # print(\"Test:\\n\", test_df['Label_Num'].value_counts(normalize=True).sort_index())\n\n    def _prepare_features(self, df, fit=False):\n        X = df.drop(['Label_Num'] + self.non_numeric_cols, axis=1)\n        y = df['Label_Num']\n        if fit:\n            X = self.scaler.fit_transform(X)\n        else:\n            X = self.scaler.transform(X)\n        # return self.create_sequences(X, y)\n        return X, y\n        \n    def create_sequences(self, X, y):\n        sequences = []\n        labels = []\n        y_values = y.values if hasattr(y, 'values') else y  # Convert to numpy array if pandas Series\n        for i in range(len(X) - self.sequence_length):\n            seq = X[i:i+self.sequence_length]\n            sequences.append(seq)\n            labels.append(y_values[i+self.sequence_length-1])\n        return np.array(sequences), np.array(labels)\n       \n    def setup(self, stage=None):\n        self.scaler = StandardScaler()\n        # self.scaler.fit(self.X_train.reshape(-1, self.X_train.shape[-1]))\n        \n        # self.X_train = self.scaler.transform(self.X_train.reshape(-1, self.X_train.shape[-1])).reshape(self.X_train.shape)\n        # self.X_val = self.scaler.transform(self.X_val.reshape(-1, self.X_val.shape[-1])).reshape(self.X_val.shape)\n        # self.X_test = self.scaler.transform(self.X_test.reshape(-1, self.X_test.shape[-1])).reshape(self.X_test.shape)\n        \n        # self.train_dataset = TensorDataset(torch.FloatTensor(self.X_train), torch.LongTensor(self.y_train))\n        # self.val_dataset = TensorDataset(torch.FloatTensor(self.X_val), torch.LongTensor(self.y_val))\n        # self.test_dataset = TensorDataset(torch.FloatTensor(self.X_test), torch.LongTensor(self.y_test))\n\n        self.train_dataset = TimeSeriesDataset(\n            data=torch.FloatTensor(self.X_train),\n            sequence_length=self.sequence_length,\n            target_idx=torch.LongTensor(self.y_train)\n        )\n        \n        self.val_dataset = TimeSeriesDataset(\n            data=torch.FloatTensor(self.X_val),\n            sequence_length=self.sequence_length,\n            target_idx=torch.LongTensor(self.y_val)\n        )\n        \n        self.test_dataset = TimeSeriesDataset(\n            data=torch.FloatTensor(self.X_test),\n            sequence_length=self.sequence_length,\n            target_idx=torch.LongTensor(self.y_test)\n        )\n            \n    def train_dataloader(self):\n        if self.oversample:\n            class_counts = np.bincount(self.y_train)\n            weights = 1. / class_counts[self.y_train]\n            sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n        else:\n            sampler = RandomSampler(self.train_dataset)\n            \n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            sampler=sampler,\n            num_workers=self.num_workers,\n            persistent_workers=True, \n            # persistent_workers=False, # better for tpu\n            pin_memory=True\n        )\n    # c=0\n    def val_dataloader(self):\n        # print(c)\n        # c+=1\n        return DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=self.num_workers,\n            pin_memory=True\n            # pin_memory=False # better for tpu\n        )\n    \n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=self.num_workers,\n            pin_memory=True\n            # pin_memory=False # TPU \n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.566278Z","iopub.execute_input":"2025-10-27T08:54:11.566453Z","iopub.status.idle":"2025-10-27T08:54:11.591886Z","shell.execute_reply.started":"2025-10-27T08:54:11.566438Z","shell.execute_reply":"2025-10-27T08:54:11.591293Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class TimeSeriesDataset(Dataset):\n    def __init__(self, data, sequence_length, target_idx=None):\n        \"\"\"\n        Dataset for time series data that creates sequences on-the-fly.\n \n        Args:\n            data: Input data tensor of shape (n_samples, n_features)\n            sequence_length: Length of sequences to create\n            target_idx: Optional tensor of target indices. If None, uses the last position in sequence\n        \"\"\"\n        self.data = data\n        self.sequence_length = sequence_length\n        self.target_idx = target_idx\n \n    def __len__(self):\n        return len(self.data)\n \n    def __getitem__(self, idx):\n        # Calculate start index for the sequence\n        start_idx = max(0, idx - self.sequence_length + 1)\n        \n        # Get the sequence\n        sequence = self.data[start_idx:idx + 1]\n        \n        # Ensure sequence is 2D [seq_len, features]\n        if sequence.dim() == 1:\n            sequence = sequence.unsqueeze(0)  # Add sequence length dimension if missing\n        \n        # Pad the beginning if needed\n        if len(sequence) < self.sequence_length:\n            padding = torch.zeros(self.sequence_length - len(sequence), sequence.shape[1])\n            sequence = torch.cat([padding, sequence], dim=0)\n        \n        # Get target\n        target = self.target_idx[idx] if self.target_idx is not None else -1\n        \n        return sequence, target\n\n\n\nclass GRUModel(pl.LightningModule):\n    def __init__(self, input_size, num_classes, config):\n        super().__init__()\n        self.save_hyperparameters()\n\n        # Temporary storage for step outputs\n        self.train_outputs = []\n        self.val_outputs = []\n\n        self.gru = nn.GRU(\n            input_size=input_size,\n            hidden_size=config.model.hidden_size,\n            num_layers=config.model.num_layers,\n            batch_first=True,\n            dropout=config.model.dropout if config.model.num_layers > 1 else 0\n        )\n        \n        self.gru_ln = nn.LayerNorm(config.model.hidden_size)\n\n        self.dense = nn.Sequential(\n            nn.Linear(config.model.hidden_size, config.model.dense_units[0]),\n            nn.LayerNorm(config.model.dense_units[0]),\n            nn.ReLU(),\n            nn.Dropout(config.model.dropout),\n            nn.Linear(config.model.dense_units[0], config.model.dense_units[1]),\n            nn.LayerNorm(config.model.dense_units[1]),\n            nn.ReLU(),\n            nn.Dropout(config.model.dropout)\n        )\n        \n        self.output = nn.Linear(config.model.dense_units[1], num_classes)\n        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n    def forward(self, x):\n        gru_out, _ = self.gru(x)\n        gru_out = gru_out[:, -1, :]\n        gru_out = self.gru_ln(gru_out)\n        features = self.dense(gru_out)\n        return self.output(features)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.criterion(logits, y)\n        acc = (logits.argmax(dim=1) == y).float().mean()\n\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n\n        # Save for epoch-end\n        self.train_outputs.append({\n            'loss': loss.detach(),\n            'correct': (logits.argmax(dim=1) == y).sum().detach(),\n            'total': len(y)\n        })\n\n        return loss\n\n    def on_train_epoch_end(self):\n        print(f\"✅ Finished Epoch {self.current_epoch+1}\")\n        if not self.train_outputs:\n            return\n\n        avg_loss = torch.stack([x['loss'] for x in self.train_outputs]).mean()\n        correct = sum([x['correct'] for x in self.train_outputs])\n        total = sum([x['total'] for x in self.train_outputs])\n        epoch_acc = correct / total\n\n        self.log('train_epoch_loss', avg_loss, prog_bar=True)\n        self.log('train_acc_epoch', epoch_acc*100, prog_bar=True)\n        self.train_outputs.clear()\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.criterion(logits, y)\n        acc = (logits.argmax(dim=1) == y).float().mean()\n\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n\n        # Save for epoch-end\n        self.val_outputs.append({\n            'val_loss': loss.detach(),\n            'correct': (logits.argmax(dim=1) == y).sum().detach(),\n            'total': len(y)\n        })\n\n        return loss\n\n    def on_validation_epoch_end(self):\n        if not self.val_outputs:\n            return\n\n        avg_loss = torch.stack([x['val_loss'] for x in self.val_outputs]).mean()\n        correct = sum([x['correct'] for x in self.val_outputs])\n        total = sum([x['total'] for x in self.val_outputs])\n        epoch_acc = (correct / total)*100\n\n        self.log('val_loss', avg_loss, prog_bar=True)\n        self.log('val_acc', epoch_acc, prog_bar=True)\n        self.val_outputs.clear()\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.criterion(logits, y)\n        acc = (logits.argmax(dim=1) == y).float().mean()\n\n        self.log('test_loss', loss)\n        self.log('test_acc', acc*100)\n\n        return {'test_loss': loss, 'preds': logits.argmax(dim=1), 'targets': y}\n\n    def configure_optimizers(self):\n        return optim.AdamW(\n            self.parameters(),\n            lr=self.hparams.config.model.learning_rate,\n            weight_decay=self.hparams.config.model.weight_decay\n        )\n\n\ndef init_wandb():\n    user_secrets = UserSecretsClient()\n    wandb_api_key = user_secrets.get_secret(\"mohammad_wandb_secret\")\n    wandb.login(key=wandb_api_key)\n    \n    run = wandb.init(\n        project=config.wandb.project,\n        entity=config.wandb.entity,\n        tags=config.wandb.tags,\n        notes=config.wandb.notes,\n        config={\n            \"input_size\": None,\n            \"num_classes\": None,\n            \"sequence_length\": config.training.sequence_length,\n            # \"train_samples\": config.training.max_train_samples,\n            # \"val_samples\": config.training.max_val_samples,\n            # \"test_samples\": config.training.max_test_samples,\n            \"model_config\": dict(config.model),\n            \"training_config\": dict(config.training)\n        }\n    )\n    \n    wandb_logger = WandbLogger(\n        experiment=run,\n        log_model='all'\n    )\n    \n    return wandb_logger, run","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.592970Z","iopub.execute_input":"2025-10-27T08:54:11.593297Z","iopub.status.idle":"2025-10-27T08:54:11.616344Z","shell.execute_reply.started":"2025-10-27T08:54:11.593242Z","shell.execute_reply":"2025-10-27T08:54:11.615785Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import threading, time, psutil\n\ntry:\n    import pynvml\n    pynvml.nvmlInit()\n    GPU_AVAILABLE = True\nexcept:\n    GPU_AVAILABLE = False\n\ndef monitor_resources(process, peaks, interval=0.2):\n    \"\"\"Monitor CPU + GPU memory usage in a background thread.\"\"\"\n    peaks[\"cpu\"] = 0.0\n    peaks[\"gpu\"] = 0.0\n    \n    handle = None\n    if GPU_AVAILABLE:\n        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n    \n    while getattr(threading.current_thread(), \"running\", True):\n        try:\n            cpu_mem = process.memory_info().rss / (1024 ** 2)\n            gpu_mem = 0.0\n            if GPU_AVAILABLE:\n                gpu_mem = pynvml.nvmlDeviceGetMemoryInfo(handle).used / (1024 ** 2)\n            peaks[\"cpu\"] = max(peaks[\"cpu\"], cpu_mem)\n            peaks[\"gpu\"] = max(peaks[\"gpu\"], gpu_mem)\n        except psutil.NoSuchProcess:\n            break\n        time.sleep(interval)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.617149Z","iopub.execute_input":"2025-10-27T08:54:11.617393Z","iopub.status.idle":"2025-10-27T08:54:11.638385Z","shell.execute_reply.started":"2025-10-27T08:54:11.617369Z","shell.execute_reply":"2025-10-27T08:54:11.637839Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# print(f\"{not NO_NODE_FEATURE}_1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.639109Z","iopub.execute_input":"2025-10-27T08:54:11.639659Z","iopub.status.idle":"2025-10-27T08:54:11.653309Z","shell.execute_reply.started":"2025-10-27T08:54:11.639637Z","shell.execute_reply":"2025-10-27T08:54:11.652486Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def main():\n    # wandb_logger, run = init_wandb()\n    \n    data_module = NIDSDataModule(config)\n    data_module.prepare_data()\n    data_module.setup()\n    \n    sample_x, _ = next(iter(data_module.train_dataloader()))\n    input_size = sample_x.shape[2]\n    num_classes = len(data_module.classes)\n    \n    # run.config.update({\n    #     \"input_size\": input_size,\n    #     \"num_classes\": num_classes\n    # })\n    \n    model = GRUModel(input_size, num_classes, config)\n    \n    early_stopping = EarlyStopping(\n        monitor='val_loss',\n        patience=config.training.early_stopping_patience,\n        mode='min'\n    )\n    \n    checkpoint_callback = ModelCheckpoint(\n        monitor='val_acc',\n        mode='max',\n        save_top_k=1,\n        dirpath='checkpoints',\n        filename='best_model'\n    )\n \n    trainer = pl.Trainer(\n        precision=16,\n        # logger=wandb_logger,\n        max_epochs=config.training.max_epochs,\n        callbacks=[early_stopping, checkpoint_callback],\n        deterministic=True,\n        gradient_clip_val=1.0,\n        enable_progress_bar=True,\n        log_every_n_steps=1000\n    )\n    \n    # start_time = time.time()\n    # process = psutil.Process()\n    print(\"------------- start training ---------------------\")\n    \n    # Measure start time and memory\n    cpu_mem_used=gpu_mem_used=elapsed_time=0\n    process = psutil.Process(os.getpid())\n    cpu_mem_before = process.memory_info().rss / (1024 ** 2)\n    handle = None\n    if GPU_AVAILABLE:\n        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n    if GPU_AVAILABLE:\n        gpu_mem_before = pynvml.nvmlDeviceGetMemoryInfo(handle).used / (1024 ** 2)\n    \n    process = psutil.Process(os.getpid())\n    peaks = {}\n    \n    monitor_thread = threading.Thread(target=monitor_resources, args=(process, peaks))\n    monitor_thread.running = True\n    monitor_thread.start()\n    \n    start_time = time.time()\n    # Train model\n    trainer.fit(model, datamodule=data_module)\n    print(\"------------- end training ---------------------\")\n    print(\"------------- start testing ---------------------\")\n    # Test model\n    test_results = trainer.test(model, datamodule=data_module)\n\n\n    # End time and memory\n    elapsed_time = time.time() - start_time\n    # Stop thread safely\n    monitor_thread.running = False\n    monitor_thread.join()\n    \n    peak_cpu = peaks.get(\"cpu\", 0.0)\n    peak_gpu = peaks.get(\"gpu\", 0.0)\n    cpu_mem_used=peak_cpu-cpu_mem_before\n    gpu_mem_used=peak_gpu-gpu_mem_before\n    \n    # end_time = time.time()\n    # time_consumption = end_time - start_time\n    # memory_consumption_mb = process.memory_info().rss / (1024 * 1024)\n    \n    print(\"------------- end testing ---------------------\")\n    # Collect all predictions and targets for final evaluation\n    test_loader = data_module.test_dataloader()\n    all_preds = []\n    all_targets = []\n    all_probs = []  # <-- store probabilities here\n    criterion = torch.nn.CrossEntropyLoss()\n    test_loss_sum=0\n    total_samples=0\n    \n    model.eval()\n    with torch.no_grad():\n        for batch in test_loader:\n            x, y = batch\n            y_hat = model(x)\n            preds = torch.argmax(y_hat, dim=1)\n            probs = torch.softmax(y_hat, dim=1).cpu().numpy()  # <-- probabilities\n            \n            loss = criterion(y_hat, y)\n            test_loss_sum += loss.item() * x.size(0)\n            total_samples += x.size(0)\n            \n            all_probs.extend(probs)\n            all_preds.extend(preds.cpu().numpy())\n            all_targets.extend(y.cpu().numpy())\n    \n    class_names = data_module.classes.tolist()\n    # metrics calculation\n    print(\"------------- metric calculation ---------------------\")\n    test_acc = accuracy_score(all_targets, all_preds)\n    test_f1 = f1_score(all_targets, all_preds, average='weighted')\n    test_recall = recall_score(all_targets, all_preds, average='weighted')\n    test_precision = precision_score(all_targets, all_preds, average='weighted')\n    test_loss_OLD = test_results[0]['test_loss'] if 'test_loss' in test_results[0] else None\n    test_loss = test_loss_sum / total_samples\n    print(test_loss_OLD)\n    print(test_loss)\n\n    all_probs = np.array(all_probs)\n    \n    try:\n        if all_probs.shape[1] == 2:\n            # Binary classification → probability of positive class\n            auc_score = roc_auc_score(all_targets, all_probs[:, 1])\n        else:\n            # Multi-class classification\n            auc_score = roc_auc_score(all_targets, all_probs, multi_class='ovr')\n    except Exception as e:\n        print(f\"AUC computation failed: {e}\")\n        auc_score = None\n\n    \n    # False Positive / False Negative Rate\n    cm = confusion_matrix(all_targets, all_preds)\n    cr = classification_report(\n        all_targets, all_preds, digits=4, output_dict=True, zero_division=0)\n    report = classification_report(\n        all_targets, all_preds, digits=4, output_dict=False, zero_division=0)\n    # weighted_f1 = f1_score(all_targets, all_preds,\n    #                        average=\"weighted\") * 100\n\n    # results_fpr_fnr = calculate_fpr_fnr_with_global(cm)\n    # fpr = results_fpr_fnr[\"global\"][\"FPR\"]\n    # fnr = results_fpr_fnr[\"global\"][\"FNR\"]\n\n    # results = {\n    #     \"test_weighted_f1\": weighted_f1,\n    #     \"test_auc\": auc_score * 100 if auc_score is not None else None,\n    #     \"test_fpr\": fpr,\n    #     \"test_fnr\": fnr,\n    #     \"classification_report\": cr,\n    #     \"results_fpr_fnr\": results_fpr_fnr\n    # }\n    # os.makedirs(\"temp\", exist_ok=True)\n    # json_path = os.path.join(\"temp\", f\"LSTM_results.json\")\n    # with open(json_path, \"w\") as f:\n    #     json.dump(results, f, indent=4)\n        \n    FP = cm.sum(axis=0) - np.diag(cm)\n    FN = cm.sum(axis=1) - np.diag(cm)\n    TP = np.diag(cm)\n    TN = cm.sum() - (FP + FN + TP)\n    fpr = FP.sum() / (FP.sum() + TN.sum())\n    fnr = FN.sum() / (FN.sum() + TP.sum())\n    # --- Per-class FPR/FNR ---\n    per_class_fpr = np.where((FP + TN) > 0, FP / (FP + TN), 0.0)\n    per_class_fnr = np.where((FN + TP) > 0, FN / (FN + TP), 0.0)\n    \n    # Convert to dict with class names\n    fpr_dict = {class_names[i]: per_class_fpr[i] for i in range(len(class_names))}\n    fnr_dict = {class_names[i]: per_class_fnr[i] for i in range(len(class_names))}\n\n    metrics_dict = {\n        \"Test Accuracy\": test_acc,\n        \"F1 Score\": test_f1,\n        \"Test Loss\": test_loss,\n        \"Recall\": test_recall,\n        \"Precision\": test_precision,\n        \"AUC\": auc_score,\n        \"False Positive Rate\": fpr,\n        \"False Negative Rate\": fnr,\n        \"Time Consumption (s)\": elapsed_time,\n        # \"Memory Consumption (MB)\": memory_consumption_mb\n        \"CPU_Peak_MB\": peak_cpu,\n        \"GPU_Peak_MB\": peak_gpu,\n        \"cpu_mem_used\":cpu_mem_used,\n        \"gpu_mem_used\":gpu_mem_used,\n    }\n    # Print metrics\n    print(\"------------- final evaluation metric ---------------------\")\n    for k, v in metrics_dict.items():\n        print(f\"{k}: {v}\")\n\n    metrics_df = pd.DataFrame([metrics_dict])\n\n    class_names = [str(c) for c in data_module.label_encoder.classes_]\n    print(\"--------------- class names --------------------\")\n    print(class_names)\n    # Generate classification report dict once\n    report = classification_report(\n        all_targets,\n        all_preds,\n        target_names=class_names,\n        output_dict=True\n    )\n    for i, cls in enumerate(class_names):\n        report[cls][\"FPR\"] = per_class_fpr[i]\n        report[cls][\"FNR\"] = per_class_fnr[i]\n\n    # Optionally, also store global ones\n    report[\"macro avg\"][\"FPR\"] = fpr\n    report[\"macro avg\"][\"FNR\"] = fnr\n    report[\"weighted avg\"][\"FPR\"] = np.average(per_class_fpr, weights=cm.sum(axis=1))\n    report[\"weighted avg\"][\"FNR\"] = np.average(per_class_fnr, weights=cm.sum(axis=1))\n        \n    print(\"Classification Report:\")\n    print(classification_report(all_targets, all_preds, target_names=class_names))\n    \n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(all_targets, all_preds))\n    \n    \n    print(\"------------- classification report dict -------------\")\n    print(report)\n    final_report = pd.DataFrame(report).transpose()\n    metrics_df = pd.DataFrame([metrics_dict])\n    merged = pd.concat([final_report, metrics_df], axis=0)\n    \n    merged.to_csv(os.path.join(\"/kaggle/working/\",f\"GRU_{dataset_name}__NODEFEATURES-{not NO_NODE_FEATURE}__report.csv\"))\n    # Create a wandb Table for the classification report\n    # report_table = wandb.Table(columns=[\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"])\n    # for class_name in class_names:\n    #     report_table.add_data(\n    #         class_name,\n    #         report[class_name][\"precision\"],\n    #         report[class_name][\"recall\"],\n    #         report[class_name][\"f1-score\"],\n    #         report[class_name][\"support\"]\n    #     )\n    \n    # # Add weighted averages\n    # report_table.add_data(\n    #     \"Weighted Avg\",\n    #     report[\"weighted avg\"][\"precision\"],\n    #     report[\"weighted avg\"][\"recall\"],\n    #     report[\"weighted avg\"][\"f1-score\"],\n    #     report[\"weighted avg\"][\"support\"]\n    # )\n    # print(\"empty\")\n    # wandb.log({\"classification_report\": report_table})\n    \n    # Finish wandb run\n    # wandb.finish()\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T08:54:11.655155Z","iopub.execute_input":"2025-10-27T08:54:11.655334Z","execution_failed":"2025-10-27T09:38:28.064Z"}},"outputs":[{"name":"stdout","text":"--------------------- cic_ids_2017-parquet -----------------------\n--------------------- Centralities Calculations  -----------------------\nClean data\nReset index after cleaning\nIdentify non-numeric columns\nEncode labels\n--------------------- Centralities Calculations starting-----------------------\ncalculated betweenness\ncalculated degree\ncalculated closeness\ncalculated pagerank\ncalculated k_truss\n==>> features_dicts: ('betweenness', 19129)\n==>> features_dicts: ('degree', 19129)\n==>> features_dicts: ('pagerank', 19129)\n==>> features_dicts: ('closeness', 19129)\n==>> features_dicts: ('k_truss', 19129)\n--------------------------  writting the DataFrame to /kaggle/working/cic_ids_2017_with_centralities.parquet ----------------------\n--------------------------DataFrame written to /kaggle/working/cic_ids_2017_with_centralities.parquet --------------------------\n\n===== Class Distribution =====\nAttack\nBENIGN                        2271122\nDoS Hulk                       230123\nPortScan                       158804\nDDoS                           128025\nDoS GoldenEye                   10293\nFTP-Patator                      7935\nSSH-Patator                      5897\nDoS slowloris                    5796\nDoS Slowhttptest                 5499\nBot                              1956\nWeb Attack � Brute Force         1507\nWeb Attack � XSS                  652\nInfiltration                       36\nWeb Attack � Sql Injection         21\nHeartbleed                         11\nName: count, dtype: int64\nInitialize scaler\nTrain/Val/Test split\n------------- start training ---------------------\n--------------------- cic_ids_2017-parquet -----------------------\n--------------------- Centralities Extractions  -----------------------\n\n===== Class Distribution =====\nAttack\nBENIGN                        2271122\nDoS Hulk                       230123\nPortScan                       158804\nDDoS                           128025\nDoS GoldenEye                   10293\nFTP-Patator                      7935\nSSH-Patator                      5897\nDoS slowloris                    5796\nDoS Slowhttptest                 5499\nBot                              1956\nWeb Attack � Brute Force         1507\nWeb Attack � XSS                  652\nInfiltration                       36\nWeb Attack � Sql Injection         21\nHeartbleed                         11\nName: count, dtype: int64\nInitialize scaler\nTrain/Val/Test split\n","output_type":"stream"},{"name":"stderr","text":"2025-10-27 09:04:38.946803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761555879.389046      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761555879.515571      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447578f8d569444382f800d4cd83167e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"✅ Finished Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"✅ Finished Epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"✅ Finished Epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"✅ Finished Epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"✅ Finished Epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"✅ Finished Epoch 6\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(new_path)\nif not os.path.exists(new_path):\n    print(\"it didn't exist yet\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-27T09:38:28.065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}