{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:26:55.563374Z",
     "iopub.status.busy": "2025-10-02T09:26:55.562826Z",
     "iopub.status.idle": "2025-10-02T09:27:18.874089Z",
     "shell.execute_reply": "2025-10-02T09:27:18.873468Z",
     "shell.execute_reply.started": "2025-10-02T09:26:55.563348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset, WeightedRandomSampler, RandomSampler\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import warnings\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import time\n",
    "import psutil\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:27:18.876140Z",
     "iopub.status.busy": "2025-10-02T09:27:18.875465Z",
     "iopub.status.idle": "2025-10-02T09:27:19.608992Z",
     "shell.execute_reply": "2025-10-02T09:27:19.608243Z",
     "shell.execute_reply.started": "2025-10-02T09:27:18.876121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import igraph as ig\n",
    "# change 1.02\n",
    "# import /kaggle/input/centrality_network/pytorch/default/1 as network\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/centrality_network/pytorch/default/1\")\n",
    "\n",
    "from network_features import separate_graph, cal_betweenness_centrality, cal_k_core, cal_k_truss\n",
    "from CommCentralityCode import comm_centreality\n",
    "from modularity_vitality import modularity_vitality\n",
    "\n",
    "sys.path.append(\"/kaggle/input/githubrepofiles/pytorch/default/1\")\n",
    "from src.dataset.dataset_info import datasets\n",
    "\n",
    "# change 1.04\n",
    "def add_centralities(df, new_path, graph_path, dataset, cn_measures, network_features):\n",
    "# def add_centralities(df, new_path, graph_path, dataset, cn_measures):\n",
    "        # change 1.05\n",
    "    # G = nx.from_pandas_edgelist(df, source=\"Src IP\",target=\"Dst IP\", create_using=nx.DiGraph())\n",
    "    if NO_NODE_FEATURE:\n",
    "        print(\"NO node features added\")\n",
    "        return df\n",
    "    G = nx.from_pandas_edgelist( df, source=dataset.src_ip_col, target=dataset.dst_ip_col, create_using=nx.DiGraph())\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    for node in G.nodes():\n",
    "        G.nodes[node]['label'] = node\n",
    "\n",
    "    G1 = ig.Graph.from_networkx(G)\n",
    "    labels = [G.nodes[node]['label'] for node in G.nodes()]\n",
    "    G1.vs['label'] = labels\n",
    "\n",
    "    part = G1.community_infomap()\n",
    "    communities = []\n",
    "    for com in part:\n",
    "        communities.append([G1.vs[node_index]['label'] for node_index in com])\n",
    "\n",
    "    community_labels = {}\n",
    "    for i, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            community_labels[node] = i\n",
    "\n",
    "    nx.set_node_attributes(G, community_labels, \"new_community\")\n",
    "\n",
    "    intra_graph, inter_graph = separate_graph(G, communities)\n",
    "\n",
    "    if \"betweenness\" in cn_measures:\n",
    "        nx.set_node_attributes(G, cal_betweenness_centrality(G), \"betweenness\")\n",
    "        print(\"calculated betweenness\")\n",
    "    if \"local_betweenness\" in cn_measures:\n",
    "        nx.set_node_attributes(G, cal_betweenness_centrality(\n",
    "            intra_graph), \"local_betweenness\")\n",
    "        print(\"calculated local_betweenness\")\n",
    "    if \"global_betweenness\" in cn_measures:\n",
    "        nx.set_node_attributes(G, cal_betweenness_centrality(\n",
    "            inter_graph), \"global_betweenness\")\n",
    "        print(\"calculated global_betweenness\")\n",
    "    if \"degree\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.degree_centrality(G), \"degree\")\n",
    "        print(\"calculated degree\")\n",
    "    if \"local_degree\" in cn_measures:\n",
    "        nx.set_node_attributes(\n",
    "            G, nx.degree_centrality(intra_graph), \"local_degree\")\n",
    "        print(\"calculated local_degree\")\n",
    "    if \"global_degree\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.degree_centrality(\n",
    "            inter_graph), \"global_degree\")\n",
    "        print(\"calculated global_degree\")\n",
    "    if \"eigenvector\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.eigenvector_centrality(\n",
    "            G, max_iter=600), \"eigenvector\")\n",
    "        print(\"calculated eigenvector\")\n",
    "    if \"local_eigenvector\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.eigenvector_centrality(\n",
    "            intra_graph), \"local_eigenvector\")\n",
    "        print(\"calculated local_eigenvector\")\n",
    "    if \"global_eigenvector\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.eigenvector_centrality(\n",
    "            inter_graph), \"global_eigenvector\")\n",
    "        print(\"calculated global_eigenvector\")\n",
    "    if \"closeness\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.closeness_centrality(G), \"closeness\")\n",
    "        print(\"calculated closeness\")\n",
    "    if \"local_closeness\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.closeness_centrality(\n",
    "            intra_graph), \"local_closeness\")\n",
    "        print(\"calculated local_closeness\")\n",
    "    if \"global_closeness\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.closeness_centrality(\n",
    "            inter_graph), \"global_closeness\")\n",
    "        print(\"calculated global_closeness\")\n",
    "    if \"pagerank\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.pagerank(G, alpha=0.85), \"pagerank\")\n",
    "        print(\"calculated pagerank\")\n",
    "    if \"local_pagerank\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.pagerank(\n",
    "            intra_graph, alpha=0.85), \"local_pagerank\")\n",
    "        print(\"calculated local_pagerank\")\n",
    "    if \"global_pagerank\" in cn_measures:\n",
    "        nx.set_node_attributes(G, nx.pagerank(\n",
    "            inter_graph, alpha=0.85), \"global_pagerank\")\n",
    "        print(\"calculated global_pagerank\")\n",
    "    if \"k_core\" in cn_measures:\n",
    "        nx.set_node_attributes(G, cal_k_core(G), \"k_core\")\n",
    "        print(\"calculated k_core\")\n",
    "    if \"k_truss\" in cn_measures:\n",
    "        nx.set_node_attributes(G, cal_k_truss(G), \"k_truss\")\n",
    "        print(\"calculated k_truss\")\n",
    "    if \"Comm\" in cn_measures:\n",
    "        nx.set_node_attributes(\n",
    "            G, comm_centreality(G, community_labels), \"Comm\")\n",
    "        print(\"calculated Comm\")\n",
    "    if \"mv\" in cn_measures:\n",
    "        nx.set_node_attributes(G, modularity_vitality(G1, part), \"mv\")\n",
    "        print(\"calculated mv\")\n",
    "\n",
    "    # nx.write_gexf(G, graph_path)\n",
    "\n",
    "    features_dicts = {}\n",
    "    for measure in cn_measures:\n",
    "        features_dicts[measure] = nx.get_node_attributes(G, measure)\n",
    "        print(f\"==>> features_dicts: {measure , len(features_dicts[measure])}\")\n",
    "\n",
    "    for feature in network_features:\n",
    "        if feature[:3] == \"src\":\n",
    "            df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(\n",
    "                row[dataset.src_ip_col], -1), axis=1)\n",
    "            # df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(\n",
    "                # row['Src Ip'], -1), axis=1)\n",
    "        if feature[:3] == \"dst\":\n",
    "            df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(\n",
    "                row[dataset.dst_ip_col], -1), axis=1)\n",
    "            # df[feature] = df.apply(lambda row: features_dicts[feature[4:]].get(row['Dst IP'], -1), axis=1)\n",
    "    print(f\"--------------------------  writting the DataFrame to {new_path} ----------------------\")\n",
    "    df.to_parquet(new_path)\n",
    "    print(f\"--------------------------DataFrame written to {new_path} --------------------------\")\n",
    "    # print(df.columns)\n",
    "    # return network_features\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:27:19.610396Z",
     "iopub.status.busy": "2025-10-02T09:27:19.609842Z",
     "iopub.status.idle": "2025-10-02T09:27:19.614087Z",
     "shell.execute_reply": "2025-10-02T09:27:19.613193Z",
     "shell.execute_reply.started": "2025-10-02T09:27:19.610376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# name = \"cic_ton_iot_5_percent\"\n",
    "# name = \"cic_ton_iot\"\n",
    "# name = \"cic_ids_2017_5_percent\"\n",
    "name = \"cic_ids_2017\"\n",
    "NO_NODE_FEATURE=False # False: centrality added  True: centality not used\n",
    "\n",
    "dataset = datasets[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:27:19.616261Z",
     "iopub.status.busy": "2025-10-02T09:27:19.615959Z",
     "iopub.status.idle": "2025-10-02T09:27:19.641798Z",
     "shell.execute_reply": "2025-10-02T09:27:19.641019Z",
     "shell.execute_reply.started": "2025-10-02T09:27:19.616235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CHANGE 1.02\n",
    "new_path = os.path.join(\"/kaggle/working/\",f\"{name}_with_centralities.parquet\")\n",
    "graph_path = os.path.join(\"/kaggle/working/\",f\"{name}_graph.gpickle\")\n",
    "# cn_measures = [\"degree\", \"betweenness\", \"closeness\", \"eigenvector\"]\n",
    "cn_measures = [\"betweenness\", \"degree\", \"pagerank\", \"closeness\", \"k_truss\"]\n",
    "network_features = ['src_betweenness', 'dst_betweenness', 'src_degree', 'dst_degree', 'src_pagerank', 'dst_pagerank', 'src_closeness', 'dst_closeness', 'src_k_truss', 'dst_k_truss']\n",
    "if name==\"cic_ids_2017\":\n",
    "    # Optimized Configuration\n",
    "    config = OmegaConf.create({\n",
    "        \"wandb\": {\n",
    "            \"project\": \"DL-NIDS-2--cic-ids-2017\",\n",
    "            \"entity\": \"mohammad-fleity-lebanese-university\",\n",
    "            \"tags\": [\"GRU\", \"CIC-IDS-2017\", \"PyTorch\"],\n",
    "            \"notes\": \"Optimized GRU for network intrusion detection\",\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"hidden_size\": 128,          # Increased capacity\n",
    "            \"num_layers\": 2,             # Deeper network\n",
    "            \"dropout\": 0.4,              # Stronger regularization\n",
    "            \"dense_units\": [128, 64],    # Better feature extraction\n",
    "            \"learning_rate\": 0.0001,     # Slower learning\n",
    "            \"weight_decay\": 1e-4         # Stronger L2 regularization\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"sequence_length\": 5,        # Longer temporal context\n",
    "            \"batch_size\": 256,           # Larger batches\n",
    "            \"max_epochs\": 15,            # More training time\n",
    "            # \"max_epochs\": 1,            # More training time\n",
    "            \"early_stopping_patience\": 7,# More patience\n",
    "            \"oversample\": True,          # Class balancing\n",
    "            \"gpus\": 1 if torch.cuda.is_available() else 0,\n",
    "            \"train_size\": 0.7,           # Proper train/val split\n",
    "            \"val_size\": 0.15             # 70/15/15 split\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"raw\": \"cic_ids_2017.parquet\",\n",
    "            \"num_workers\": 4\n",
    "        }\n",
    "    })\n",
    "    dataset_name=\"CIC_IDS_2017\"\n",
    "elif name ==\"cic_ton_iot\":\n",
    "    config = OmegaConf.create({\n",
    "        \"wandb\": {\n",
    "            \"project\": \"DL-NIDS-2--cic-ton-iot\",\n",
    "            \"entity\": \"mohammad-fleity-lebanese-university\",\n",
    "            \"tags\": [\"GRU\", \"CIC-TON-IOT\", \"PyTorch\"],\n",
    "            \"notes\": \"Optimized GRU for network intrusion detection\"\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"hidden_size\": 128,          # Increased capacity\n",
    "            \"num_layers\": 2,             # Deeper network\n",
    "            \"dropout\": 0.4,              # Stronger regularization\n",
    "            \"dense_units\": [128, 64],    # Better feature extraction\n",
    "            \"learning_rate\": 0.0001,     # Slower learning\n",
    "            \"weight_decay\": 1e-4         # Stronger L2 regularization\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"sequence_length\": 5,        # Longer temporal context\n",
    "            \"batch_size\": 256,           # Larger batches\n",
    "            \"max_epochs\": 15,            # More training time\n",
    "            # \"max_epochs\": 1,            # More training time\n",
    "            \"early_stopping_patience\": 7,# More patience\n",
    "            \"oversample\": True,          # Class balancing\n",
    "            \"gpus\": 1 if torch.cuda.is_available() else 0,\n",
    "            \"train_size\": 0.7,           # Proper train/val split\n",
    "            \"val_size\": 0.15             # 70/15/15 split\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"raw\": \"cic_ton_iot.parquet\",\n",
    "            \"num_workers\": 4\n",
    "        }\n",
    "    })\n",
    "    dataset_name=\"CIC_TON_IOT\"\n",
    "    \n",
    "elif name ==\"cic_ids_2017_5_percent\": # THIS IS JUST FOR TESTING THE FUNCTIONALITIES FASTER\n",
    "    config = OmegaConf.create({\n",
    "        \"wandb\": {\n",
    "            \"project\": \"DL-NIDS-2--cic-ton-iot\",\n",
    "            \"entity\": \"mohammad-fleity-lebanese-university\",\n",
    "            \"tags\": [\"GRU\", \"CIC-TON-IOT\", \"PyTorch\"],\n",
    "            \"notes\": \"Optimized GRU for network intrusion detection\"\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"hidden_size\": 128,          # Increased capacity\n",
    "            \"num_layers\": 2,             # Deeper network\n",
    "            \"dropout\": 0.4,              # Stronger regularization\n",
    "            \"dense_units\": [128, 64],    # Better feature extraction\n",
    "            \"learning_rate\": 0.0001,     # Slower learning\n",
    "            \"weight_decay\": 1e-4         # Stronger L2 regularization\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"sequence_length\": 5,        # Longer temporal context\n",
    "            \"batch_size\": 256,           # Larger batches\n",
    "            \"max_epochs\": 1,            # More training time\n",
    "            \"early_stopping_patience\": 7,# More patience\n",
    "            \"oversample\": True,          # Class balancing\n",
    "            \"gpus\": 1 if torch.cuda.is_available() else 0,\n",
    "            \"train_size\": 0.7,           # Proper train/val split\n",
    "            \"val_size\": 0.15             # 70/15/15 split\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"raw\": \"cic_ids_2017_5_percent.parquet\",\n",
    "            \"num_workers\": 4\n",
    "        }\n",
    "    })\n",
    "    dataset_name=\"cic_ids_2017_5_percent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:27:19.642978Z",
     "iopub.status.busy": "2025-10-02T09:27:19.642718Z",
     "iopub.status.idle": "2025-10-02T09:27:19.666947Z",
     "shell.execute_reply": "2025-10-02T09:27:19.666390Z",
     "shell.execute_reply.started": "2025-10-02T09:27:19.642954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_fpr_fnr_with_global(cm):\n",
    "    \"\"\"\n",
    "    Calculate FPR and FNR for each class and globally for a multi-class confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "        cm (numpy.ndarray): Confusion matrix of shape (num_classes, num_classes).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing per-class and global FPR and FNR.\n",
    "    \"\"\"\n",
    "    num_classes = cm.shape[0]\n",
    "    results = {\"per_class\": {}, \"global\": {}}\n",
    "\n",
    "    # Initialize variables for global calculation\n",
    "    total_TP = 0\n",
    "    total_FP = 0\n",
    "    total_FN = 0\n",
    "    total_TN = 0\n",
    "\n",
    "    # Per-class calculation\n",
    "    for class_idx in range(num_classes):\n",
    "        TP = cm[class_idx, class_idx]\n",
    "        FN = np.sum(cm[class_idx, :]) - TP\n",
    "        FP = np.sum(cm[:, class_idx]) - TP\n",
    "        TN = np.sum(cm) - (TP + FP + FN)\n",
    "\n",
    "        # Calculate FPR and FNR for this class\n",
    "        FPR = FP / (FP + TN) if (FP + TN) != 0 else None\n",
    "        FNR = FN / (TP + FN) if (TP + FN) != 0 else None\n",
    "\n",
    "        # Store per-class results\n",
    "        results[\"per_class\"][class_idx] = {\"FPR\": FPR, \"FNR\": FNR}\n",
    "\n",
    "        # Update global counts\n",
    "        total_TP += TP\n",
    "        total_FP += FP\n",
    "        total_FN += FN\n",
    "        total_TN += TN\n",
    "\n",
    "    # Global calculation\n",
    "    global_FPR = total_FP / \\\n",
    "        (total_FP + total_TN) if (total_FP + total_TN) != 0 else None\n",
    "    global_FNR = total_FN / \\\n",
    "        (total_FN + total_TP) if (total_FN + total_TP) != 0 else None\n",
    "\n",
    "    results[\"global\"][\"FPR\"] = global_FPR\n",
    "    results[\"global\"][\"FNR\"] = global_FNR\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:27:19.667857Z",
     "iopub.status.busy": "2025-10-02T09:27:19.667693Z",
     "iopub.status.idle": "2025-10-02T09:27:19.694043Z",
     "shell.execute_reply": "2025-10-02T09:27:19.693259Z",
     "shell.execute_reply.started": "2025-10-02T09:27:19.667843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class NIDSDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.batch_size = config.training.batch_size\n",
    "        self.sequence_length = config.training.sequence_length\n",
    "        self.num_workers = config.data.num_workers\n",
    "        self.oversample = config.training.oversample\n",
    "        self.non_numeric_cols=[]\n",
    "        self.scaler=None\n",
    "        self.alpha = 0.5\n",
    "\n",
    "    def prepare_data(self):\n",
    "        print(f\"--------------------- {name}-parquet -----------------------\")\n",
    "        if not os.path.exists(new_path):\n",
    "            print(\"--------------------- Centralities Calculations  -----------------------\")\n",
    "            if dataset_name==\"CIC_IDS_2017\":\n",
    "                df = pd.read_parquet(os.path.join('/kaggle/input/cic-ids-2017-parquet', self.config.data.raw))\n",
    "                # print(\"--------------------- cic-ids-2017-parquet -----------------------\")\n",
    "            elif dataset_name==\"CIC_TON_IOT\":\n",
    "                df = pd.read_parquet(os.path.join('/kaggle/input/cic-ton-iot-parquet', self.config.data.raw))\n",
    "                # print(\"--------------------- cic-ton-iot-parquet -----------------------\")\n",
    "            elif dataset_name==\"cic_ids_2017_5_percent\":\n",
    "                df = pd.read_parquet(os.path.join('/kaggle/input/cic-ids-2017-5-percent', self.config.data.raw))\n",
    "                # print(\"--------------------- /kaggle/input/cic-ids-2017-5-percent -----------------------\")\n",
    "    \n",
    "            print(\"Clean data\")\n",
    "            df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            df.dropna(inplace=True)\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            \n",
    "            print(\"Reset index after cleaning\")\n",
    "            df = df.reset_index(drop=True)\n",
    "            \n",
    "            print(\"Identify non-numeric columns\")\n",
    "            self.non_numeric_cols = ['Label', 'Timestamp', 'Flow ID', 'Src IP', \n",
    "                                     'Src Port', 'Attack', 'Dst IP', 'Dst Port', 'Protocol']\n",
    "            self.non_numeric_cols = [col for col in self.non_numeric_cols if col in df.columns]\n",
    "    \n",
    "    \n",
    "            print(\"Encode labels\")\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            df['Label_Num'] = self.label_encoder.fit_transform(df['Attack'])\n",
    "            self.classes = self.label_encoder.classes_\n",
    "            \n",
    "            # print(\"Initialize scaler\")\n",
    "            # self.scaler = StandardScaler()\n",
    "            # CHANGE 1.01\n",
    "            # print(\"Calculate Centralities start\")\n",
    "            print(\"--------------------- Centralities Calculations starting-----------------------\")\n",
    "            df = add_centralities(\n",
    "                df= df,\n",
    "                new_path=new_path,\n",
    "                graph_path=graph_path,\n",
    "                dataset=dataset,\n",
    "                cn_measures=cn_measures,\n",
    "                network_features=network_features\n",
    "            )\n",
    "        else:\n",
    "            # print(new_path,\" exist now!\")\n",
    "            print(\"--------------------- Centralities Extractions  -----------------------\")\n",
    "            df = pd.read_parquet(new_path)\n",
    "        # CHANGES TO REMOVE use only for test with 5_perecent \n",
    "        if dataset_name==\"cic_ids_2017_5_percent\":\n",
    "            multiplier = 5  # change as you wish\n",
    "    \n",
    "            target_substring = \"Sql Injection\"\n",
    "            target_rows = df[df['Attack'].str.contains(target_substring, na=False)]\n",
    "            \n",
    "            if target_rows.empty:\n",
    "                print(f\"Warning: no rows found matching '{target_substring}' in train set.\")\n",
    "            else:\n",
    "                duplicated_block = pd.concat([target_rows] * (multiplier - 1), ignore_index=True)\n",
    "                df = pd.concat([df, duplicated_block], ignore_index=True)\n",
    "                print(f\"Duplicated target class rows by factor {multiplier}. New count:\",\n",
    "                  df['Attack'].str.contains(target_substring, na=False).sum())\n",
    "            \n",
    "            \n",
    "            \n",
    "        print(\"\\n===== Class Distribution =====\")\n",
    "        counts = df[\"Attack\"].value_counts()\n",
    "        print(counts)\n",
    "        # print()\n",
    "        print(\"Initialize scaler\")\n",
    "        self.scaler = StandardScaler()\n",
    "        print(\"Train/Val/Test split\")\n",
    "        train_df, test_df = train_test_split(\n",
    "            df,\n",
    "            test_size=1 - self.config.training.train_size,\n",
    "            random_state=42,\n",
    "            stratify=df['Label_Num']\n",
    "        )\n",
    "        val_df, test_df = train_test_split(\n",
    "            test_df,\n",
    "            test_size=0.5,\n",
    "            random_state=42,\n",
    "            stratify=test_df['Label_Num']\n",
    "        )\n",
    "        # Reset indices after splitting\n",
    "        train_df = train_df.reset_index(drop=True)\n",
    "        val_df = val_df.reset_index(drop=True)\n",
    "        test_df = test_df.reset_index(drop=True)\n",
    "        \n",
    "        # Use `fit=True` only for training data\n",
    "        self.X_train, self.y_train = self._prepare_features(train_df, fit=True)\n",
    "        self.X_val, self.y_val = self._prepare_features(val_df, fit=False)\n",
    "        self.X_test, self.y_test = self._prepare_features(test_df, fit=False)\n",
    "        # print(\"Val:\\n\", val_df['Label_Num'].value_counts(normalize=True).sort_index())\n",
    "        # print(\"Test:\\n\", test_df['Label_Num'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "    def _prepare_features(self, df, fit=False):\n",
    "        X = df.drop(['Label_Num'] + self.non_numeric_cols, axis=1)\n",
    "        y = df['Label_Num']\n",
    "        if fit:\n",
    "            X = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            X = self.scaler.transform(X)\n",
    "        # return self.create_sequences(X, y)\n",
    "        return X, y\n",
    "        \n",
    "    def create_sequences(self, X, y):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        y_values = y.values if hasattr(y, 'values') else y  # Convert to numpy array if pandas Series\n",
    "        for i in range(len(X) - self.sequence_length):\n",
    "            seq = X[i:i+self.sequence_length]\n",
    "            sequences.append(seq)\n",
    "            labels.append(y_values[i+self.sequence_length-1])\n",
    "        return np.array(sequences), np.array(labels)\n",
    "       \n",
    "    def setup(self, stage=None):\n",
    "        self.scaler = StandardScaler()\n",
    "        # self.scaler.fit(self.X_train.reshape(-1, self.X_train.shape[-1]))\n",
    "        \n",
    "        # self.X_train = self.scaler.transform(self.X_train.reshape(-1, self.X_train.shape[-1])).reshape(self.X_train.shape)\n",
    "        # self.X_val = self.scaler.transform(self.X_val.reshape(-1, self.X_val.shape[-1])).reshape(self.X_val.shape)\n",
    "        # self.X_test = self.scaler.transform(self.X_test.reshape(-1, self.X_test.shape[-1])).reshape(self.X_test.shape)\n",
    "        \n",
    "        # self.train_dataset = TensorDataset(torch.FloatTensor(self.X_train), torch.LongTensor(self.y_train))\n",
    "        # self.val_dataset = TensorDataset(torch.FloatTensor(self.X_val), torch.LongTensor(self.y_val))\n",
    "        # self.test_dataset = TensorDataset(torch.FloatTensor(self.X_test), torch.LongTensor(self.y_test))\n",
    "\n",
    "        self.train_dataset = TimeSeriesDataset(\n",
    "            data=torch.FloatTensor(self.X_train),\n",
    "            sequence_length=self.sequence_length,\n",
    "            target_idx=torch.LongTensor(self.y_train)\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = TimeSeriesDataset(\n",
    "            data=torch.FloatTensor(self.X_val),\n",
    "            sequence_length=self.sequence_length,\n",
    "            target_idx=torch.LongTensor(self.y_val)\n",
    "        )\n",
    "        \n",
    "        self.test_dataset = TimeSeriesDataset(\n",
    "            data=torch.FloatTensor(self.X_test),\n",
    "            sequence_length=self.sequence_length,\n",
    "            target_idx=torch.LongTensor(self.y_test)\n",
    "        )\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        if self.oversample:\n",
    "            class_counts = np.bincount(self.y_train)\n",
    "            weights = 1. / class_counts[self.y_train]\n",
    "            sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "        else:\n",
    "            sampler = RandomSampler(self.train_dataset)\n",
    "            \n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=self.num_workers,\n",
    "            persistent_workers=True, \n",
    "            # persistent_workers=False, # better for tpu\n",
    "            pin_memory=True\n",
    "        )\n",
    "    # c=0\n",
    "    def val_dataloader(self):\n",
    "        # print(c)\n",
    "        # c+=1\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "            # pin_memory=False # better for tpu\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "            # pin_memory=False # TPU \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:27:19.694980Z",
     "iopub.status.busy": "2025-10-02T09:27:19.694819Z",
     "iopub.status.idle": "2025-10-02T09:27:19.721563Z",
     "shell.execute_reply": "2025-10-02T09:27:19.721024Z",
     "shell.execute_reply.started": "2025-10-02T09:27:19.694966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length, target_idx=None):\n",
    "        \"\"\"\n",
    "        Dataset for time series data that creates sequences on-the-fly.\n",
    " \n",
    "        Args:\n",
    "            data: Input data tensor of shape (n_samples, n_features)\n",
    "            sequence_length: Length of sequences to create\n",
    "            target_idx: Optional tensor of target indices. If None, uses the last position in sequence\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.sequence_length = sequence_length\n",
    "        self.target_idx = target_idx\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate start index for the sequence\n",
    "        start_idx = max(0, idx - self.sequence_length + 1)\n",
    "        \n",
    "        # Get the sequence\n",
    "        sequence = self.data[start_idx:idx + 1]\n",
    "        \n",
    "        # Ensure sequence is 2D [seq_len, features]\n",
    "        if sequence.dim() == 1:\n",
    "            sequence = sequence.unsqueeze(0)  # Add sequence length dimension if missing\n",
    "        \n",
    "        # Pad the beginning if needed\n",
    "        if len(sequence) < self.sequence_length:\n",
    "            padding = torch.zeros(self.sequence_length - len(sequence), sequence.shape[1])\n",
    "            sequence = torch.cat([padding, sequence], dim=0)\n",
    "        \n",
    "        # Get target\n",
    "        target = self.target_idx[idx] if self.target_idx is not None else -1\n",
    "        \n",
    "        return sequence, target\n",
    "\n",
    "\n",
    "\n",
    "class GRUModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes, config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Temporary storage for step outputs\n",
    "        self.train_outputs = []\n",
    "        self.val_outputs = []\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=config.model.hidden_size,\n",
    "            num_layers=config.model.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=config.model.dropout if config.model.num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.gru_ln = nn.LayerNorm(config.model.hidden_size)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(config.model.hidden_size, config.model.dense_units[0]),\n",
    "            nn.LayerNorm(config.model.dense_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.model.dropout),\n",
    "            nn.Linear(config.model.dense_units[0], config.model.dense_units[1]),\n",
    "            nn.LayerNorm(config.model.dense_units[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.model.dropout)\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Linear(config.model.dense_units[1], num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        gru_out = gru_out[:, -1, :]\n",
    "        gru_out = self.gru_ln(gru_out)\n",
    "        features = self.dense(gru_out)\n",
    "        return self.output(features)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # Save for epoch-end\n",
    "        self.train_outputs.append({\n",
    "            'loss': loss.detach(),\n",
    "            'correct': (logits.argmax(dim=1) == y).sum().detach(),\n",
    "            'total': len(y)\n",
    "        })\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        print(f\"✅ Finished Epoch {self.current_epoch+1}\")\n",
    "        if not self.train_outputs:\n",
    "            return\n",
    "\n",
    "        avg_loss = torch.stack([x['loss'] for x in self.train_outputs]).mean()\n",
    "        correct = sum([x['correct'] for x in self.train_outputs])\n",
    "        total = sum([x['total'] for x in self.train_outputs])\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        self.log('train_epoch_loss', avg_loss, prog_bar=True)\n",
    "        self.log('train_acc_epoch', epoch_acc*100, prog_bar=True)\n",
    "        self.train_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        # Save for epoch-end\n",
    "        self.val_outputs.append({\n",
    "            'val_loss': loss.detach(),\n",
    "            'correct': (logits.argmax(dim=1) == y).sum().detach(),\n",
    "            'total': len(y)\n",
    "        })\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if not self.val_outputs:\n",
    "            return\n",
    "\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in self.val_outputs]).mean()\n",
    "        correct = sum([x['correct'] for x in self.val_outputs])\n",
    "        total = sum([x['total'] for x in self.val_outputs])\n",
    "        epoch_acc = (correct / total)*100\n",
    "\n",
    "        self.log('val_loss', avg_loss, prog_bar=True)\n",
    "        self.log('val_acc', epoch_acc, prog_bar=True)\n",
    "        self.val_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc*100)\n",
    "\n",
    "        return {'test_loss': loss, 'preds': logits.argmax(dim=1), 'targets': y}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.config.model.learning_rate,\n",
    "            weight_decay=self.hparams.config.model.weight_decay\n",
    "        )\n",
    "\n",
    "\n",
    "def init_wandb():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_api_key = user_secrets.get_secret(\"mohammad_wandb_secret\")\n",
    "    wandb.login(key=wandb_api_key)\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project=config.wandb.project,\n",
    "        entity=config.wandb.entity,\n",
    "        tags=config.wandb.tags,\n",
    "        notes=config.wandb.notes,\n",
    "        config={\n",
    "            \"input_size\": None,\n",
    "            \"num_classes\": None,\n",
    "            \"sequence_length\": config.training.sequence_length,\n",
    "            # \"train_samples\": config.training.max_train_samples,\n",
    "            # \"val_samples\": config.training.max_val_samples,\n",
    "            # \"test_samples\": config.training.max_test_samples,\n",
    "            \"model_config\": dict(config.model),\n",
    "            \"training_config\": dict(config.training)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    wandb_logger = WandbLogger(\n",
    "        experiment=run,\n",
    "        log_model='all'\n",
    "    )\n",
    "    \n",
    "    return wandb_logger, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:27:19.722582Z",
     "iopub.status.busy": "2025-10-02T09:27:19.722325Z",
     "iopub.status.idle": "2025-10-02T09:28:43.148118Z",
     "shell.execute_reply": "2025-10-02T09:28:43.147276Z",
     "shell.execute_reply.started": "2025-10-02T09:27:19.722561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # wandb_logger, run = init_wandb()\n",
    "    \n",
    "    data_module = NIDSDataModule(config)\n",
    "    data_module.prepare_data()\n",
    "    data_module.setup()\n",
    "    \n",
    "    sample_x, _ = next(iter(data_module.train_dataloader()))\n",
    "    input_size = sample_x.shape[2]\n",
    "    num_classes = len(data_module.classes)\n",
    "    \n",
    "    # run.config.update({\n",
    "    #     \"input_size\": input_size,\n",
    "    #     \"num_classes\": num_classes\n",
    "    # })\n",
    "    \n",
    "    model = GRUModel(input_size, num_classes, config)\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config.training.early_stopping_patience,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_top_k=1,\n",
    "        dirpath='checkpoints',\n",
    "        filename='best_model'\n",
    "    )\n",
    " \n",
    "    trainer = pl.Trainer(\n",
    "        precision=16,\n",
    "        # logger=wandb_logger,\n",
    "        max_epochs=config.training.max_epochs,\n",
    "        callbacks=[early_stopping, checkpoint_callback],\n",
    "        deterministic=True,\n",
    "        gradient_clip_val=1.0,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=1000\n",
    "    )\n",
    "    \n",
    "    # Measure start time and memory\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process()\n",
    "    print(\"------------- start training ---------------------\")\n",
    "    # Train model\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    print(\"------------- end training ---------------------\")\n",
    "    print(\"------------- start testing ---------------------\")\n",
    "    # Test model\n",
    "    test_results = trainer.test(model, datamodule=data_module)\n",
    "    print(\"------------- end testing ---------------------\")\n",
    "    # Collect all predictions and targets for final evaluation\n",
    "    test_loader = data_module.test_dataloader()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []  # <-- store probabilities here\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    test_loss_sum=0\n",
    "    total_samples=0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            y_hat = model(x)\n",
    "            preds = torch.argmax(y_hat, dim=1)\n",
    "            probs = torch.softmax(y_hat, dim=1).cpu().numpy()  # <-- probabilities\n",
    "            \n",
    "            loss = criterion(y_hat, y)\n",
    "            test_loss_sum += loss.item() * x.size(0)\n",
    "            total_samples += x.size(0)\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "    \n",
    "    # End time and memory\n",
    "    end_time = time.time()\n",
    "    time_consumption = end_time - start_time\n",
    "    memory_consumption_mb = process.memory_info().rss / (1024 * 1024)\n",
    "    class_names = data_module.classes.tolist()\n",
    "    # metrics calculation\n",
    "    print(\"------------- metric calculation ---------------------\")\n",
    "    test_acc = accuracy_score(all_targets, all_preds)\n",
    "    test_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    test_recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "    test_precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "    test_loss_OLD = test_results[0]['test_loss'] if 'test_loss' in test_results[0] else None\n",
    "    test_loss = test_loss_sum / total_samples\n",
    "    print(test_loss_OLD)\n",
    "    print(test_loss)\n",
    "\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    try:\n",
    "        if all_probs.shape[1] == 2:\n",
    "            # Binary classification → probability of positive class\n",
    "            auc_score = roc_auc_score(all_targets, all_probs[:, 1])\n",
    "        else:\n",
    "            # Multi-class classification\n",
    "            auc_score = roc_auc_score(all_targets, all_probs, multi_class='ovr')\n",
    "    except Exception as e:\n",
    "        print(f\"AUC computation failed: {e}\")\n",
    "        auc_score = None\n",
    "\n",
    "    \n",
    "    # False Positive / False Negative Rate\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    cr = classification_report(\n",
    "        all_targets, all_preds, digits=4, output_dict=True, zero_division=0)\n",
    "    report = classification_report(\n",
    "        all_targets, all_preds, digits=4, output_dict=False, zero_division=0)\n",
    "    # weighted_f1 = f1_score(all_targets, all_preds,\n",
    "    #                        average=\"weighted\") * 100\n",
    "\n",
    "    # results_fpr_fnr = calculate_fpr_fnr_with_global(cm)\n",
    "    # fpr = results_fpr_fnr[\"global\"][\"FPR\"]\n",
    "    # fnr = results_fpr_fnr[\"global\"][\"FNR\"]\n",
    "\n",
    "    # results = {\n",
    "    #     \"test_weighted_f1\": weighted_f1,\n",
    "    #     \"test_auc\": auc_score * 100 if auc_score is not None else None,\n",
    "    #     \"test_fpr\": fpr,\n",
    "    #     \"test_fnr\": fnr,\n",
    "    #     \"classification_report\": cr,\n",
    "    #     \"results_fpr_fnr\": results_fpr_fnr\n",
    "    # }\n",
    "    # os.makedirs(\"temp\", exist_ok=True)\n",
    "    # json_path = os.path.join(\"temp\", f\"LSTM_results.json\")\n",
    "    # with open(json_path, \"w\") as f:\n",
    "    #     json.dump(results, f, indent=4)\n",
    "        \n",
    "    FP = cm.sum(axis=0) - np.diag(cm)\n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    fpr = FP.sum() / (FP.sum() + TN.sum())\n",
    "    fnr = FN.sum() / (FN.sum() + TP.sum())\n",
    "    # --- Per-class FPR/FNR ---\n",
    "    per_class_fpr = np.where((FP + TN) > 0, FP / (FP + TN), 0.0)\n",
    "    per_class_fnr = np.where((FN + TP) > 0, FN / (FN + TP), 0.0)\n",
    "    \n",
    "    # Convert to dict with class names\n",
    "    fpr_dict = {class_names[i]: per_class_fpr[i] for i in range(len(class_names))}\n",
    "    fnr_dict = {class_names[i]: per_class_fnr[i] for i in range(len(class_names))}\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Test Accuracy\": test_acc,\n",
    "        \"F1 Score\": test_f1,\n",
    "        \"Test Loss\": test_loss,\n",
    "        \"Recall\": test_recall,\n",
    "        \"Precision\": test_precision,\n",
    "        \"AUC\": auc_score,\n",
    "        \"False Positive Rate\": fpr,\n",
    "        \"False Negative Rate\": fnr,\n",
    "        \"Time Consumption (s)\": time_consumption,\n",
    "        \"Memory Consumption (MB)\": memory_consumption_mb\n",
    "    }\n",
    "    # Print metrics\n",
    "    print(\"------------- final evaluation metric ---------------------\")\n",
    "    for k, v in metrics_dict.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "\n",
    "    # metrics_df.to_csv(\"/kaggle/working/metrics_results.csv\", index=False)\n",
    "\n",
    "    # Log final test metrics\n",
    "    # wandb.log({\n",
    "    #     'test_acc': test_acc,\n",
    "    #     'test_f1': test_f1,\n",
    "    #     'test_loss': test_results[0]['test_loss']\n",
    "    # })\n",
    "    \n",
    "    # Confusion matrix and classification report\n",
    "    # class_names = data_module.classes.tolist()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    # wandb.log({\n",
    "    #     \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "    #         y_true=all_targets,\n",
    "    #         preds=all_preds,\n",
    "    #         class_names=class_names,\n",
    "    #         title=\"Confusion Matrix\"\n",
    "    #     )\n",
    "    # })\n",
    "    \n",
    "    # Classification Report\n",
    "    # Get class names from the data module's label encoder\n",
    "    # class_names = list(data_module.label_encoder.classes_)\n",
    "    \n",
    "    # Generate classification report with names instead of numbers\n",
    "    # class_names = list(data_module.label_encoder.classes_)\n",
    "    class_names = [str(c) for c in data_module.label_encoder.classes_]\n",
    "    print(\"--------------- class names --------------------\")\n",
    "    print(class_names)\n",
    "    # Generate classification report dict once\n",
    "    report = classification_report(\n",
    "        all_targets,\n",
    "        all_preds,\n",
    "        target_names=class_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "    for i, cls in enumerate(class_names):\n",
    "        report[cls][\"FPR\"] = per_class_fpr[i]\n",
    "        report[cls][\"FNR\"] = per_class_fnr[i]\n",
    "\n",
    "    # Optionally, also store global ones\n",
    "    report[\"macro avg\"][\"FPR\"] = fpr\n",
    "    report[\"macro avg\"][\"FNR\"] = fnr\n",
    "    report[\"weighted avg\"][\"FPR\"] = np.average(per_class_fpr, weights=cm.sum(axis=1))\n",
    "    report[\"weighted avg\"][\"FNR\"] = np.average(per_class_fnr, weights=cm.sum(axis=1))\n",
    "        \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_targets, all_preds, target_names=class_names))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_targets, all_preds))\n",
    "    \n",
    "    \n",
    "    print(\"------------- classification report dict -------------\")\n",
    "    print(report)\n",
    "    final_report = pd.DataFrame(report).transpose()\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "    merged = pd.concat([final_report, metrics_df], axis=0)\n",
    "    \n",
    "    merged.to_csv(os.path.join(\"/kaggle/working/\",f\"GRU_{dataset_name}_report.csv\"))\n",
    "    # Create a wandb Table for the classification report\n",
    "    # report_table = wandb.Table(columns=[\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"])\n",
    "    # for class_name in class_names:\n",
    "    #     report_table.add_data(\n",
    "    #         class_name,\n",
    "    #         report[class_name][\"precision\"],\n",
    "    #         report[class_name][\"recall\"],\n",
    "    #         report[class_name][\"f1-score\"],\n",
    "    #         report[class_name][\"support\"]\n",
    "    #     )\n",
    "    \n",
    "    # # Add weighted averages\n",
    "    # report_table.add_data(\n",
    "    #     \"Weighted Avg\",\n",
    "    #     report[\"weighted avg\"][\"precision\"],\n",
    "    #     report[\"weighted avg\"][\"recall\"],\n",
    "    #     report[\"weighted avg\"][\"f1-score\"],\n",
    "    #     report[\"weighted avg\"][\"support\"]\n",
    "    # )\n",
    "    # print(\"empty\")\n",
    "    # wandb.log({\"classification_report\": report_table})\n",
    "    \n",
    "    # Finish wandb run\n",
    "    # wandb.finish()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:30:19.234822Z",
     "iopub.status.busy": "2025-10-02T09:30:19.233925Z",
     "iopub.status.idle": "2025-10-02T09:30:19.239409Z",
     "shell.execute_reply": "2025-10-02T09:30:19.238793Z",
     "shell.execute_reply.started": "2025-10-02T09:30:19.234788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(new_path)\n",
    "if not os.path.exists(new_path):\n",
    "    print(\"it didn't exist yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4775518,
     "sourceId": 8089266,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4775527,
     "sourceId": 8089281,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7994437,
     "sourceId": 12650227,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 399557,
     "modelInstanceId": 379672,
     "sourceId": 470644,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 460697,
     "modelInstanceId": 444208,
     "sourceId": 593572,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
